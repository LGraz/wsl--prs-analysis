<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
  <front>
    <article-meta>
      <title-group>
        <article-title>PRS Analysis for WSL</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <contrib-id contrib-id-type="orcid">0009-0003-5147-8370</contrib-id>
          <name>
            <surname>Graz</surname>
            <given-names>Lukas</given-names>
          </name>
          <string-name>Lukas Graz</string-name>
          <role vocab="https://credit.niso.org" vocab-term="writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
          <xref ref-type="aff" rid="aff-1">a</xref>
          <xref ref-type="corresp" rid="cor-1">*</xref>
        </contrib>
      </contrib-group>
      <aff id="aff-1">
        <institution-wrap>
          <institution>ETH Zurich</institution>
        </institution-wrap>
        <city>Zurich</city>
        <state>Switzerland</state>
        <ext-link ext-link-type="uri" xlink:href="www.ethz.ch">www.ethz.ch</ext-link>
      </aff>
      <author-notes>
        <corresp id="cor-1"/>
      </author-notes>
      <history/>
    </article-meta>
  </front>
  <body>
    <p>For the <bold>release notes</bold> see the corresponding
<ext-link ext-link-type="uri" xlink:href="https://github.com/LGraz/wsl--prs-analysis/releases">GitHub</ext-link>
page</p>
    <sec id="data-preparation">
      <title>Data Preparation</title>
      <sec id="train-test-split-for-inference">
        <title>Train Test Split for Inference</title>
        <p>Data was split into training and test sets (50/50) for hypothesis
    testing to ensure valid inference after feature selection.</p>
      </sec>
      <sec id="missing-values">
        <title>Missing Values</title>
        <p>Missing value imputation was performed using MissForest
    doi:10.1093/bioinformatics/btr597. This method leverages conditional
    dependencies between variables to predict missing values through an
    iterative random forest approach.</p>
        <p>To avoid introducing spurious correlations between different
    variable sets, we imputed the following data groups separately:</p>
        <list list-type="bullet">
          <list-item>
            <p>PRS variables on the complete dataset</p>
          </list-item>
          <list-item>
            <p>Mediators on training data only</p>
          </list-item>
          <list-item>
            <p>GIS variables on training data only</p>
          </list-item>
          <list-item>
            <p>Mediators for prediction analysis</p>
          </list-item>
          <list-item>
            <p>GIS variables for prediction analysis</p>
          </list-item>
          <list-item>
            <p>PRS variables for prediction analysis</p>
          </list-item>
        </list>
        <p>Mediators and GIS variables were intentionally not imputed on the
    test set to maintain valid inference, as MissForest does not provide
    a mechanism to propagate imputation uncertainty. An alternative
    would be the <monospace>mice</monospace>-routine, which could be
    implemented in future analyses. Missing values in the test set
    predictors remained untreated, which is justified under the missing
    completely at random (MCAR) assumption—where missing values occur
    independently of all other variables.</p>
        <p>For the prediction analysis, fewer statistical assumptions are
    required, so using the MissForest approach does not violate any
    assumptions.</p>
        <p>PRS variables could have been imputed separately for
    training/test sets and prediction analysis, but we prioritized
    simplicity as these variables serve only as response variables.</p>
        <p>Additionally, we compared MissForest with simpler imputation
    methods (variable-wise and observation-wise mean imputation) for the
    PRS variables. Results confirmed that MissForest consistently
    outperformed these alternatives.</p>
      </sec>
    </sec>
    <sec id="main-analysis">
      <title>Main Analysis</title>
      <sec id="response-variable-selection">
        <title>Response Variable Selection</title>
        <list list-type="bullet">
          <list-item>
            <p>Aggregated mean</p>
          </list-item>
          <list-item>
            <p>FA (Fascination)</p>
          </list-item>
          <list-item>
            <p>BA (Being Away)</p>
          </list-item>
          <list-item>
            <p>EC (Extent Coherence)</p>
          </list-item>
          <list-item>
            <p>ES (Compatibility)</p>
          </list-item>
        </list>
        <p><bold>PCA Verification</bold> of this approach. Key findings:</p>
        <list list-type="bullet">
          <list-item>
            <p>Data can be well approximated with 3-4 dimensions</p>
          </list-item>
          <list-item>
            <p>First dimension is close to weighted average of all variables
        (correlation &gt;0.99)</p>
          </list-item>
          <list-item>
            <p>EC (Extent Coherence) shows most divergence (see PC2)</p>
          </list-item>
          <list-item>
            <p>FA (Fascination) and BA (Being Away) show similarity (see
        PC1-PC3)</p>
          </list-item>
          <list-item>
            <p>Aggregated PRS variables justified by PCA results (similar
        rotation values), supporting use of mean</p>
          </list-item>
        </list>
      </sec>
      <sec id="prediction-analysis-with-machine-learning-methods">
        <title>Prediction Analysis with Machine Learning Methods</title>
        <p>Details and results in
    <ext-link ext-link-type="uri" xlink:href="notebooks/mlr3.qmd">the
    notebook</ext-link>.</p>
        <p>This section investigates predictive relationships between
    Perceived Restorativeness Scale (PRS) variables, mediator variables,
    and Geographical Information System (GIS) variables using various
    machine learning approaches. We employed a systematic methodology to
    quantify the predictive power of different variable
    combinations.</p>
        <sec id="methodological-approach">
          <title>Methodological Approach</title>
          <p>We evaluated multiple machine learning models using the mlr3
      framework (cite doi:10.21105/joss.01903) :</p>
          <list list-type="bullet">
            <list-item>
              <p>Linear models (baseline)</p>
            </list-item>
            <list-item>
              <p>XGBoost (gradient boosting with tree-based models and
          hyperparameter tuning for learning rate and tree depth) (cite
          arxiv:1603.02754)</p>
            </list-item>
            <list-item>
              <p>Random Forests (with default parameters) (cite
          doi:10.1023/A:1010933404324)</p>
            </list-item>
          </list>
          <p>Performance was measured as percentage of explained variance on
      hold-out data, calculated as (1 - MSE/Variance(y)), where MSE
      represents mean squared error.</p>
        </sec>
        <sec id="model-combinations">
          <title>Model Combinations</title>
          <p>To systematically explore predictive relationships, we tested
      four model configurations:</p>
          <list list-type="order">
            <list-item>
              <p>PRS ~ GIS: Predicting PRS variables using only GIS
          variables</p>
            </list-item>
            <list-item>
              <p>PRS ~ GIS + Mediators: Predicting PRS variables using both
          GIS and mediator variables</p>
            </list-item>
            <list-item>
              <p>PRS ~ Mediators: Predicting PRS variables using only
          mediator variables</p>
            </list-item>
            <list-item>
              <p>Mediators ~ GIS: Predicting mediator variables using GIS
          variables</p>
            </list-item>
          </list>
        </sec>
        <sec id="results">
          <title>Results</title>
          <list list-type="bullet">
            <list-item>
              <p>GIS shows limited predictive power for PRS on ES (5%
          variance explained)</p>
            </list-item>
            <list-item>
              <p>GIS + Mediators explain 25% of PRS variance</p>
            </list-item>
            <list-item>
              <p>Mediators alone explain majority of PRS variance</p>
              <list list-type="bullet">
                <list-item>
                  <p>GIS primarily helps with ES through tree-based
              methods</p>
                </list-item>
                <list-item>
                  <p>Suggests GIS effect is more interaction-based than
              direct</p>
                </list-item>
                <list-item>
                  <p>Similar reduction in tree-based methods observed in
              BA</p>
                </list-item>
              </list>
            </list-item>
          </list>
        </sec>
      </sec>
      <sec id="hypothesis-testing-investigation-of-variable-effects-on-perceived-restorativeness-scale">
        <title>Hypothesis Testing: Investigation of Variable Effects on
    Perceived Restorativeness Scale</title>
        <p>Details and results in
    <ext-link ext-link-type="uri" xlink:href="notebooks/hypothethis-tests.qmd">the
    notebook</ext-link>.</p>
        <p>Here we investigated which variables (including their
    interactions) influence PRS variables using multiple linear
    regression. With 190 variables (counting interactions), the variance
    inflation factor (VIF) was high and the multiple testing problem
    severe. We therefore implemented a stepwise feature selection using
    Bayesian Information Criterion (BIC) on the training data, starting
    with an empty model to help computational complexity. Selected
    features were subsequently used to fit models on the test set to
    obtain valid p-values. To keep the coefficients interpretable in the
    presence of interactions, each variable is scaled to mean 0 and
    standard deviation 1.</p>
        <sec id="model-specification-and-analysis">
          <title>Model Specification and Analysis</title>
          <p>The analysis systematically explored two key relationship
      pathways:</p>
          <list list-type="order">
            <list-item>
              <p>Mediators ~ (GIS)² - examining how environmental features
          predict psychological mediators</p>
            </list-item>
            <list-item>
              <p>PRS ~ (Mediators + GIS)² - investigating how both
          environmental features and psychological mediators contribute
          to perceived restorativeness</p>
            </list-item>
          </list>
          <p>For each target variable, we constructed a separate model using
      stepwise selection and evaluated it on the test dataset.</p>
        </sec>
        <sec id="results-1">
          <title>Results</title>
          <list list-type="bullet">
            <list-item>
              <p>For HM_Noise (now removed): Continuous mediator outperforms
          categorical (scaled to mean 0, sd 1)</p>
            </list-item>
            <list-item>
              <p>Full <monospace>mice</monospace> NA-handling likely
          unnecessary</p>
              <list list-type="bullet">
                <list-item>
                  <p>Models use few variables</p>
                </list-item>
                <list-item>
                  <p>Only LNOISE shows high NA count</p>
                </list-item>
                <list-item>
                  <p>Information detection still fails</p>
                </list-item>
              </list>
            </list-item>
            <list-item>
              <p>Significant edges remain in SEM (see all interactions)</p>
            </list-item>
          </list>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
</back>
  <sub-article article-type="notebook" id="nb-1-nb-1">
    <front-stub>
      <title-group>
        <article-title>Prediction Analysis for WSL</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Graz</surname>
            <given-names>Lukas</given-names>
          </name>
          <string-name>Lukas Graz</string-name>
        </contrib>
      </contrib-group>
    </front-stub>
    <body>
      <sec specific-use="notebook-content">
        <code language="r script">source("R/data_prep.R")
</code>
        <boxed-text>
          <preformat>Number of matches per filter criteria (not disjoint)
  Headphone  PRS_all_NA    Distance Activity_NA    Duration  HMNoise_NA 
        303         226         221         102          96          96 
JourneyTime 
         20 
Keep  1494 of 2206 observations</preformat>
        </boxed-text>
        <boxed-text>
          <preformat>Imputing PRS_orig_vars</preformat>
        </boxed-text>
      </sec>
      <sec id="setup-nb-1">
        <title>Setup</title>
        <sec specific-use="notebook-content">
          <code language="r script">library(mlr3verse, quietly = TRUE)

mse &lt;- msrs(c("regr.mse"))

if (!interactive())
  lgr::get_logger("mlr3")$set_threshold("warn")

get_benchi_table &lt;- function(tasks, nfolds = 5) {
  set.seed(123)
  learners &lt;- lrns(c("regr.featureless", "regr.lm", "regr.xgboost", "regr.ranger"))
  learners$regr.xgboost$param_set$set_values(
    eta = 0.03, 
    nrounds = 300, 
    max_depth = 2
  )

  benchi &lt;- xfun::cache_rds({
    benchmark(benchmark_grid(
      tasks, 
      learners, 
      rsmp("cv", folds = nfolds)
    ))
  }, 
  file = "benchmark.rds", 
  dir = "cache/",
  hash = list(tasks, nfolds)
  )
  
  res &lt;- tidyr::pivot_wider(benchi$aggregate(mse), 
    id_cols = task_id,
    names_from = learner_id,
    values_from = regr.mse
  ) |&gt; as.data.frame()
  
  rownames(res) &lt;- res$task_id
  res &lt;- res[, -1]
  colnames(res) &lt;- gsub("regr.", "", colnames(res))
  stopifnot(any(colnames(res) == "featureless"))
  res &lt;- 1 - res / res$featureless
  res[, -1, drop = FALSE] |&gt; round(3)
}
  </code>
        </sec>
        <p>Testing prediction quality of GIS_vars -&gt; Mediators -&gt;
  PRS_vars using</p>
        <list list-type="bullet">
          <list-item>
            <p>Linear models</p>
          </list-item>
          <list-item>
            <p>Random forests (default parameters)</p>
          </list-item>
          <list-item>
            <p>XGBoost (with parameter tuning)</p>
          </list-item>
          <list-item>
            <p>FASSO (not shown since inferior)</p>
          </list-item>
        </list>
        <p>
          <bold>GIS Variables:</bold>
        </p>
        <sec specific-use="notebook-content">
          <code language="r script">GIS_vars
  </code>
          <boxed-text>
            <preformat> [1] "LCARTIF_sqrt"   "LCFOREST_sqrt"  "HETER"          "OVDIST_sqrt"   
 [5] "VIS5K_sqrt"     "RL_NDVI"        "RL_NOISE"       "DISTKM_sqrt"   
 [9] "JNYTIME_sqrt"   "STRIMP123_sqrt" "STRIMP999_sqrt"</preformat>
          </boxed-text>
        </sec>
        <p>
          <bold>Mediators:</bold>
        </p>
        <sec specific-use="notebook-content">
          <code language="r script">Mediator_vars
  </code>
          <boxed-text>
            <preformat>[1] "FEELNAT"  "LNOISE"   "LOC_SENS" "LOC_SOUN" "LOC_SCEN" "LOC_VISE" "LOC_VEGE"
[8] "LOC_FAUN"</preformat>
          </boxed-text>
        </sec>
        <sec id="prs-gis-nb-1">
          <title>PRS ~ GIS</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_GIS &lt;- lapply(PRS_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, GIS_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_GIS) 
    </code>
            <boxed-text>
              <preformat>         lm xgboost ranger
MEAN -0.001  -0.006 -0.035
FA   -0.002   0.012  0.002
BA   -0.006  -0.010 -0.022
EC    0.003  -0.027 -0.037
ES    0.047   0.041  0.025</preformat>
            </boxed-text>
          </sec>
          <p>GIS variables alone show poor predictive performance.</p>
        </sec>
        <sec id="prs-gis-mediators-nb-1">
          <title>PRS ~ GIS + Mediators</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_GIS_MED &lt;- lapply(PRS_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, Mediator_vars, GIS_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_GIS_MED) 
    </code>
            <boxed-text>
              <preformat>        lm xgboost ranger
MEAN 0.227   0.243  0.229
FA   0.235   0.259  0.251
BA   0.123   0.136  0.134
EC   0.045   0.017  0.023
ES   0.153   0.169  0.158</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="prs-mediators-nb-1">
          <title>PRS ~ Mediators</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_MED &lt;- lapply(PRS_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, Mediator_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_MED) 
    </code>
            <boxed-text>
              <preformat>        lm xgboost ranger
MEAN 0.226   0.240  0.197
FA   0.226   0.253  0.228
BA   0.135   0.150  0.109
EC   0.036   0.023 -0.018
ES   0.133   0.138  0.080</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="mediators-gis-nb-1">
          <title>Mediators ~ GIS</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_MED_by_GIS &lt;- lapply(Mediator_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, GIS_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_MED_by_GIS)
    </code>
            <boxed-text>
              <preformat>            lm xgboost ranger
FEELNAT  0.127   0.138  0.114
LNOISE   0.096   0.070  0.080
LOC_SENS 0.020  -0.004 -0.026
LOC_SOUN 0.041   0.007 -0.002
LOC_SCEN 0.039   0.051  0.022
LOC_VISE 0.008  -0.029 -0.043
LOC_VEGE 0.052   0.031  0.035
LOC_FAUN 0.057   0.063  0.047</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="legacy-code-nb-1">
          <title>Legacy Code</title>
          <sec specific-use="notebook-content">
            <code language="r script">
# Get parameter estimates for XGBoost
t &lt;- as_task_regr(
  subset(Dmlr, select = c("FEELNAT", GIS_vars)),
  target = "FEELNAT"
)

l &lt;- lrn("regr.xgboost",
  nrounds = 500  # More iterations due to lower learning rate
)

# Create search space
ps &lt;- ps(
  max_depth = p_int(2, 3),
  eta = p_dbl(0.001, 0.3, tags = "logscale")
)

# Setup tuning
instance &lt;- ti(
  task = t,
  learner = l,
  resampling = rsmp("cv", folds = 3),
  measure = msr("regr.mse"),
  terminator = trm("none"),
  search_space = ps
)

# Grid search
tuner &lt;- mlr3tuning::tnr("grid_search")
tuner$optimize(instance)
instance$result
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">
library(randomForest)

fit &lt;- lm(as.formula(paste0(
    "cbind(", paste(PRS_vars, collapse = ", "), ")",
    " ~ ",
    paste(Mediator_vars, collapse = " + ")
  )), 
  D)
coef(fit) |&gt; round(2)

rsq.lm &lt;- sapply(summary(fit), \(x) x$r.sq)
rsq.rf &lt;- sapply(PRS_vars, \(x) {
  rf &lt;- randomForest(as.formula(paste0(
    x, " ~ ", paste(Mediator_vars, collapse = " + ")
  )), 
  D, na.action = na.omit
  ) 
  rf$rsq[500]
})

cbind(lm = rsq.lm, rf = rsq.rf) |&gt; round(2)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">
autoplot(mytsk1, type = "pairs")
mytsk1 &lt;- as_task_regr(
  subset(Dmlr, select = c("FA", Mediator_vars, GIS_vars)),
  feature = c(Mediator_vars, GIS_vars),
  target = "FA",
  id = "bla"
)

lrn_xgb &lt;- lrn("regr.xgboost")
lrn_avg &lt;- lrn("regr.featureless")
splits &lt;- partition(mytsk1)
lrn_xgb$train(mytsk1, splits$train)$predict(mytsk1, splits$test)$score(mse)
lrn_avg$train(mytsk1, splits$train)$predict(mytsk1, splits$test)$score(mse)
rr &lt;- resample(mytsk1, lrn_xgb, cv3)
rr$aggregate(mse)

learners &lt;- lrns(c("regr.featureless", "regr.lm", "regr.xgboost", "regr.ranger"))
learners$regr.xgboost$param_set$set_values(eta = 0.03, nrounds = 300, max_depth = 2)
learners &lt;- c("regr.featureless", "regr.lm")
    </code>
          </sec>
        </sec>
      </sec>
    </body>
    <back>
</back>
  </sub-article>
  <sub-article article-type="notebook" id="nb-4-nb-2">
    <front-stub>
      <title-group>
        <article-title>Hypothesis Testing</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Graz</surname>
            <given-names>Lukas</given-names>
          </name>
          <string-name>Lukas Graz</string-name>
        </contrib>
      </contrib-group>
    </front-stub>
    <body>
      <sec specific-use="notebook-content">
        <code language="r script">source("R/data_prep.R")
</code>
        <boxed-text>
          <preformat>Number of matches per filter criteria (not disjoint)
  Headphone  PRS_all_NA    Distance Activity_NA    Duration  HMNoise_NA 
        303         226         221         102          96          96 
JourneyTime 
         20 
Keep  1494 of 2206 observations</preformat>
        </boxed-text>
        <boxed-text>
          <preformat>Imputing PRS_orig_vars</preformat>
        </boxed-text>
        <code language="r script">options(digits = 3)

# interactive &lt;- function() FALSE
# D_trn$HM_NOISE_nrm &lt;- scale(D_trn$HM_NOISE)
# D_tst$HM_NOISE_nrm &lt;- scale(D_tst$HM_NOISE)
## No suspicious patterns in missing data
# mice::md.pattern(D[c(Mediator_vars, GIS_vars)[nNAs&gt;0]], plot = FALSE)
# mice::md.pattern(D[PRS_orig_vars])
</code>
      </sec>
      <sec id="linear-modeling-nb-2">
        <title>Linear Modeling</title>
        <sec id="imputation-with-missforest-on-training-data-nb-2">
          <title>Imputation with MissForest on Training Data</title>
          <sec specific-use="notebook-content">
            <code language="r script">sapply(D[Mediator_vars], \(x) sum(is.na(x)))
    </code>
            <boxed-text>
              <preformat> FEELNAT   LNOISE LOC_SENS LOC_SOUN LOC_SCEN LOC_VISE LOC_VEGE LOC_FAUN 
      16      291       28       30       36       62       69       88 </preformat>
            </boxed-text>
            <code language="r script">sapply(D[GIS_vars], \(x) sum(is.na(x)))
    </code>
            <boxed-text>
              <preformat>  LCARTIF_sqrt  LCFOREST_sqrt          HETER    OVDIST_sqrt     VIS5K_sqrt 
             0              0              0              0              0 
       RL_NDVI       RL_NOISE    DISTKM_sqrt   JNYTIME_sqrt STRIMP123_sqrt 
             0              0              0             86              0 
STRIMP999_sqrt 
             0 </preformat>
            </boxed-text>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script"># Mediator imputation
D_trn[Mediator_vars] &lt;- xfun::cache_rds({
  missForest(as.matrix(D_trn[Mediator_vars]))
  }, 
  file = "Mediator_imputation.rds", 
  dir = "cache/",
  hash = list(as.matrix(D_trn[Mediator_vars]))
)$ximp |&gt; as.data.frame()

# GIS imputation (missForest)
D_trn[GIS_vars] &lt;- xfun::cache_rds({
  missForest(as.matrix(D_trn[GIS_vars]))
  }, 
  file = "GIS_imputation.rds", 
  dir = "cache/",
  hash = list(as.matrix(D_trn[GIS_vars]))
)$ximp |&gt; as.data.frame()
    </code>
          </sec>
        </sec>
        <sec id="scaling-test-data-nb-2">
          <title>Scaling Test Data</title>
          <sec specific-use="notebook-content">
            <code language="r script">all_vars &lt;- c(Mediator_vars, GIS_vars, PRS_vars)
old_scale &lt;- t(sapply(D_tst[c(all_vars)], \(x) 
  c(mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE))))

D_tst[c(all_vars)] &lt;- lapply(D_tst[c(all_vars)], scale)

old_scale
    </code>
            <boxed-text>
              <preformat>                 mean     sd
FEELNAT         6.142  1.055
LNOISE          4.210  0.747
LOC_SENS        4.098  1.016
LOC_SOUN        4.296  0.947
LOC_SCEN        3.967  1.056
LOC_VISE        4.080  1.027
LOC_VEGE        4.343  0.859
LOC_FAUN        3.298  1.365
LCARTIF_sqrt    0.271  0.269
LCFOREST_sqrt   0.454  0.311
HETER           1.305  0.402
OVDIST_sqrt    21.797 10.144
VIS5K_sqrt      3.323  1.620
RL_NDVI         0.635  0.202
RL_NOISE       41.615  9.261
DISTKM_sqrt     1.473  1.156
JNYTIME_sqrt    3.830  2.247
STRIMP123_sqrt  6.555 10.739
STRIMP999_sqrt 47.557 13.162
MEAN            4.987  0.882
FA              5.266  1.111
BA              5.141  1.157
EC              4.542  1.290
ES              5.006  1.430</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="testing-vif-nb-2">
          <title>Testing VIF</title>
          <sec specific-use="notebook-content">
            <code language="r script">car::vif(fit_PRS_MED &lt;- lm(as.formula(paste0(
  PRS_vars[1], 
  " ~ ", 
  paste(Mediator_vars, collapse = " + "), " + ",
  paste(GIS_vars,      collapse = " + ")
)), D_trn)) |&gt; summary()
    </code>
            <boxed-text>
              <preformat>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   1.21    1.46    1.94    2.03    2.24    4.99 </preformat>
            </boxed-text>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">suppressMessages(
car::vif(fit_PRS_MED &lt;- lm(as.formula(paste0(
  PRS_vars[1], 
  " ~ ", 
  "(", paste(Mediator_vars, collapse = " + "), 
     " + ", paste(GIS_vars, collapse = " + "), 
  ")^2"
)), D_trn))) |&gt; summary()
    </code>
            <boxed-text>
              <preformat>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   11.9    81.4   147.6   204.9   270.7  1391.7 </preformat>
            </boxed-text>
          </sec>
          <p>Since we model <italic>with</italic> interactions later, the
    latter VIF are relevant for us. Given that they are very high (c.f.
    median and max), we would have no hope of finding any significant
    results in the full interaction model. Therefore, we will first
    perfom a variable selection, to reduce the VIF and enable us to find
    significant effects.</p>
        </sec>
        <sec id="all-interactions-mediators-gis2-nb-2">
          <title>All Interactions: Mediators ~ (GIS)^2</title>
          <sec specific-use="notebook-content">
            <code language="r script">
# Elegant function to create coefficient tables from model summaries
library(dplyr)
    </code>
            <boxed-text>
              <preformat>
Attaching package: 'dplyr'</preformat>
            </boxed-text>
            <boxed-text>
              <preformat>The following objects are masked from 'package:stats':

    filter, lag</preformat>
            </boxed-text>
            <boxed-text>
              <preformat>The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union</preformat>
            </boxed-text>
            <code language="r script">
library(tidyr)
library(knitr)
library(purrr)

#' Create a formatted coefficient table from model summary list
#' 
#' @param model_summaries List of model summaries (e.g., output from lapply(models, summary))
#' @param sig_threshold Significance threshold for bold formatting (default: 0.001)
#' @param covariate_order Optional vector specifying order of covariates
#' @return Formatted table with models as columns and covariates as rows
create_coef_table &lt;- function(model_summaries, sig_threshold = 0.001, covariate_order = NULL) {
  
  # Extract and format coefficients for all models
  format_model_coef &lt;- function(coef_matrix, model_name) {
    estimates &lt;- coef_matrix[, "Estimate"]
    p_values &lt;- coef_matrix[, "Pr(&gt;|t|)"]
    
    # Format with significance stars (common notation)
    formatted_coef &lt;- sapply(seq_along(estimates), function(i) {
      est_str &lt;- sprintf("%.3f", estimates[i])
      stars &lt;- case_when(
        p_values[i] &lt; 0.001 ~ "***",
        p_values[i] &lt; 0.01 ~ "**",
        p_values[i] &lt; 0.05 ~ "*",
        p_values[i] &lt; 0.1 ~ ".",
        TRUE ~ ""
      )
      paste0(est_str, stars)
    })
    
    tibble(
      Model = model_name,
      Covariate = rownames(coef_matrix),
      Coefficient = formatted_coef
    )
  }
  
  # Process all models and create wide table
  coef_list &lt;- map(model_summaries, coef)
  
  results_table &lt;- map2_dfr(coef_list, names(coef_list), format_model_coef) %&gt;%
    pivot_wider(names_from = Model, values_from = Coefficient, values_fill = "")
  
  # Apply covariate ordering
  if (is.null(covariate_order)) {
    # Default: Intercept first, then alphabetical
    all_covariates &lt;- unique(results_table$Covariate)
    covariate_order &lt;- c("(Intercept)", sort(all_covariates[all_covariates != "(Intercept)"]))
  }
  
  # Filter and reorder covariates
  results_table &lt;- results_table %&gt;%
    filter(Covariate %in% covariate_order) %&gt;%
    slice(match(covariate_order, Covariate))
  
  kable(results_table, 
        format = "pipe",
        align = c("l", rep("c", ncol(results_table) - 1)))
}
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">Res3 &lt;- list()
for (mediator in Mediator_vars) {
  intercept_model &lt;- lm(as.formula(paste0(
    mediator, " ~ 1")), D_trn)
  step_model &lt;- step(intercept_model, 
    scope = as.formula(paste0(
      mediator, " ~ ", 
      "(", paste(GIS_vars, collapse = " + "), ")^2"
    )),
    trace = FALSE, k = log(nrow(D_trn))
  )
  Res3[[mediator]] &lt;- lm(formula(step_model), D_tst)
}
(ResSum3 &lt;- lapply(Res3, summary))
    </code>
            <boxed-text>
              <preformat>$FEELNAT

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-4.959 -0.391  0.264  0.607  1.685 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)            0.0618     0.0410    1.51  0.13260    
LCARTIF_sqrt          -0.1524     0.0570   -2.67  0.00770 ** 
RL_NDVI                0.1498     0.0436    3.43  0.00063 ***
OVDIST_sqrt            0.0270     0.0452    0.60  0.55112    
LCARTIF_sqrt:RL_NDVI   0.1146     0.0402    2.85  0.00446 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.948 on 733 degrees of freedom
  (9 observations deleted due to missingness)
Multiple R-squared:  0.106, Adjusted R-squared:  0.101 
F-statistic: 21.8 on 4 and 733 DF,  p-value: &lt;2e-16


$LNOISE

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.999 -0.527  0.012  0.676  1.622 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -0.00097    0.03862   -0.03    0.980    
LCARTIF_sqrt -0.12357    0.04841   -2.55    0.011 *  
RL_NOISE     -0.24203    0.04890   -4.95  9.7e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.945 on 596 degrees of freedom
  (148 observations deleted due to missingness)
Multiple R-squared:  0.11,  Adjusted R-squared:  0.107 
F-statistic: 36.6 on 2 and 596 DF,  p-value: 9.79e-16


$LOC_SENS

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.319 -0.217 -0.007  0.831  1.390 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    -0.000148   0.036675    0.00  0.99678    
HETER           0.129769   0.038233    3.39  0.00073 ***
STRIMP999_sqrt -0.072664   0.038328   -1.90  0.05837 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.993 on 730 degrees of freedom
  (14 observations deleted due to missingness)
Multiple R-squared:  0.0168,    Adjusted R-squared:  0.0141 
F-statistic: 6.22 on 2 and 730 DF,  p-value: 0.00209


$LOC_SOUN

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.623 -0.402  0.482  0.698  1.512 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   0.000403   0.036322    0.01   0.9912    
LCARTIF_sqrt -0.175213   0.037180   -4.71  2.9e-06 ***
HETER         0.109010   0.037186    2.93   0.0035 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.984 on 731 degrees of freedom
  (13 observations deleted due to missingness)
Multiple R-squared:  0.0344,    Adjusted R-squared:  0.0317 
F-statistic:   13 on 2 and 731 DF,  p-value: 2.82e-06


$LOC_SCEN

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.0383 -0.2135  0.0669  0.8101  1.8029 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.00114    0.03618   -0.03     0.97    
RL_NDVI      0.21701    0.03629    5.98  3.5e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.977 on 727 degrees of freedom
  (18 observations deleted due to missingness)
Multiple R-squared:  0.0469,    Adjusted R-squared:  0.0456 
F-statistic: 35.8 on 1 and 727 DF,  p-value: 3.48e-09


$LOC_VISE

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.0692 -0.1488 -0.0235  0.8511  1.0861 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)  -0.000356   0.037305   -0.01    0.992  
LCARTIF_sqrt -0.071106   0.037580   -1.89    0.059 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.998 on 714 degrees of freedom
  (31 observations deleted due to missingness)
Multiple R-squared:  0.00499,   Adjusted R-squared:  0.0036 
F-statistic: 3.58 on 1 and 714 DF,  p-value: 0.0589


$LOC_VEGE

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.971 -0.492  0.443  0.706  1.599 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   -0.0192     0.0378   -0.51   0.6111    
RL_NDVI        0.2195     0.0382    5.75  1.4e-08 ***
JNYTIME_sqrt  -0.1139     0.0379   -3.01   0.0027 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.98 on 671 degrees of freedom
  (73 observations deleted due to missingness)
Multiple R-squared:  0.0549,    Adjusted R-squared:  0.052 
F-statistic: 19.5 on 2 and 671 DF,  p-value: 6.03e-09


$LOC_FAUN

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-1.898 -0.914  0.300  0.796  1.744 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -0.00127    0.03685   -0.03     0.97    
LCARTIF_sqrt -0.21409    0.03697   -5.79  1.1e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.978 on 702 degrees of freedom
  (43 observations deleted due to missingness)
Multiple R-squared:  0.0456,    Adjusted R-squared:  0.0442 
F-statistic: 33.5 on 1 and 702 DF,  p-value: 1.05e-08</preformat>
            </boxed-text>
          </sec>
          <sec id="table-nb-2">
            <title>Table</title>
            <sec specific-use="notebook-content">
              <code language="r script">create_coef_table(ResSum3)
      </code>
              <table-wrap>
                <table>
                  <colgroup>
                    <col width="20%"/>
                    <col width="10%"/>
                    <col width="11%"/>
                    <col width="10%"/>
                    <col width="11%"/>
                    <col width="10%"/>
                    <col width="10%"/>
                    <col width="10%"/>
                    <col width="11%"/>
                  </colgroup>
                  <thead>
                    <tr>
                      <th align="left">Covariate</th>
                      <th align="center">FEELNAT</th>
                      <th align="center">LNOISE</th>
                      <th align="center">LOC_SENS</th>
                      <th align="center">LOC_SOUN</th>
                      <th align="center">LOC_SCEN</th>
                      <th align="center">LOC_VISE</th>
                      <th align="center">LOC_VEGE</th>
                      <th align="center">LOC_FAUN</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td align="left">(Intercept)</td>
                      <td align="center">0.062</td>
                      <td align="center">-0.001</td>
                      <td align="center">-0.000</td>
                      <td align="center">0.000</td>
                      <td align="center">-0.001</td>
                      <td align="center">-0.000</td>
                      <td align="center">-0.019</td>
                      <td align="center">-0.001</td>
                    </tr>
                    <tr>
                      <td align="left">HETER</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">0.130***</td>
                      <td align="center">0.109**</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">JNYTIME_sqrt</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">-0.114**</td>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">LCARTIF_sqrt</td>
                      <td align="center">-0.152**</td>
                      <td align="center">-0.124*</td>
                      <td align="center"/>
                      <td align="center">-0.175***</td>
                      <td align="center"/>
                      <td align="center">-0.071.</td>
                      <td align="center"/>
                      <td align="center">-0.214***</td>
                    </tr>
                    <tr>
                      <td align="left">LCARTIF_sqrt:RL_NDVI</td>
                      <td align="center">0.115**</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">OVDIST_sqrt</td>
                      <td align="center">0.027</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">RL_NDVI</td>
                      <td align="center">0.150***</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">0.217***</td>
                      <td align="center"/>
                      <td align="center">0.219***</td>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">RL_NOISE</td>
                      <td align="center"/>
                      <td align="center">-0.242***</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">STRIMP999_sqrt</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">-0.073.</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                  </tbody>
                </table>
              </table-wrap>
            </sec>
          </sec>
        </sec>
        <sec id="all-interactions-prs-mediators-gis2-nb-2">
          <title>All Interactions: PRS ~ (Mediators + GIS)^2</title>
          <sec specific-use="notebook-content">
            <code language="r script">Res4 &lt;- list()
for (prs in PRS_vars) {
  intercept_model &lt;- lm(as.formula(paste0(
    prs, " ~ 1")), D_trn)
  step_model &lt;- step(intercept_model, 
    scope = as.formula(paste0(
      prs, " ~ ", 
      "(", paste(GIS_vars, collapse = " + "), " + ", 
      paste(Mediator_vars, collapse = " + "), ")^2"
    )),
    trace = FALSE, k = log(nrow(D_trn))
  )
  Res4[[prs]] &lt;- lm(formula(step_model), D_tst)
}
(ResSum4 &lt;- lapply(Res4, summary))
    </code>
            <boxed-text>
              <preformat>$MEAN

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.8609 -0.5631 -0.0386  0.5998  2.7647 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)      -0.00762    0.03787   -0.20    0.841    
LOC_VISE          0.17314    0.04201    4.12  4.3e-05 ***
FEELNAT           0.20198    0.04293    4.70  3.2e-06 ***
LOC_SENS          0.10408    0.04234    2.46    0.014 *  
LNOISE            0.17667    0.04049    4.36  1.5e-05 ***
FEELNAT:LOC_SENS  0.05398    0.02793    1.93    0.054 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.893 on 567 degrees of freedom
  (174 observations deleted due to missingness)
Multiple R-squared:  0.192, Adjusted R-squared:  0.184 
F-statistic: 26.9 on 5 and 567 DF,  p-value: &lt;2e-16


$FA

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.391 -0.518  0.093  0.592  2.567 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)      -0.00324    0.03796   -0.09  0.93195    
LOC_VISE          0.12823    0.04125    3.11  0.00197 ** 
LOC_FAUN          0.17631    0.04167    4.23  2.7e-05 ***
LNOISE            0.13307    0.04017    3.31  0.00098 ***
RL_NDVI          -0.13265    0.03906   -3.40  0.00073 ***
FEELNAT           0.16853    0.04528    3.72  0.00022 ***
LOC_SCEN          0.16380    0.04567    3.59  0.00036 ***
FEELNAT:LOC_SCEN -0.00170    0.03148   -0.05  0.95699    
RL_NDVI:LOC_SCEN  0.02416    0.03405    0.71  0.47821    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.865 on 556 degrees of freedom
  (182 observations deleted due to missingness)
Multiple R-squared:  0.256, Adjusted R-squared:  0.245 
F-statistic: 23.9 on 8 and 556 DF,  p-value: &lt;2e-16


$BA

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.965 -0.507  0.070  0.647  2.410 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.00835    0.03572   -0.23   0.8152    
LOC_VISE     0.12213    0.04045    3.02   0.0026 ** 
FEELNAT      0.18778    0.03684    5.10  4.4e-07 ***
LOC_SENS     0.14743    0.04055    3.64   0.0003 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.948 on 700 degrees of freedom
  (43 observations deleted due to missingness)
Multiple R-squared:  0.115, Adjusted R-squared:  0.111 
F-statistic: 30.2 on 3 and 700 DF,  p-value: &lt;2e-16


$EC

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.9221 -0.5444 -0.0364  0.6855  2.3639 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   -0.00858    0.03666   -0.23  0.81510    
LOC_SENS       0.14234    0.04085    3.48  0.00052 ***
LOC_SCEN       0.00370    0.04121    0.09  0.92855    
LCFOREST_sqrt -0.08955    0.03752   -2.39  0.01724 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.986 on 719 degrees of freedom
  (24 observations deleted due to missingness)
Multiple R-squared:  0.0297,    Adjusted R-squared:  0.0257 
F-statistic: 7.34 on 3 and 719 DF,  p-value: 7.55e-05


$ES

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.492 -0.541  0.145  0.689  2.296 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     0.03146    0.04159    0.76   0.4497    
LNOISE          0.13295    0.04315    3.08   0.0022 ** 
LOC_SENS        0.09603    0.04085    2.35   0.0191 *  
DISTKM_sqrt     0.08081    0.04039    2.00   0.0459 *  
FEELNAT         0.25812    0.04639    5.56    4e-08 ***
LNOISE:FEELNAT -0.00623    0.03425   -0.18   0.8558    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.95 on 576 degrees of freedom
  (165 observations deleted due to missingness)
Multiple R-squared:  0.141, Adjusted R-squared:  0.133 
F-statistic: 18.8 on 5 and 576 DF,  p-value: &lt;2e-16</preformat>
            </boxed-text>
          </sec>
          <sec id="table-1-nb-2">
            <title>Table</title>
            <sec specific-use="notebook-content">
              <code language="r script">create_coef_table(ResSum4)
      </code>
              <table-wrap>
                <table>
                  <colgroup>
                    <col width="25%"/>
                    <col width="15%"/>
                    <col width="16%"/>
                    <col width="15%"/>
                    <col width="15%"/>
                    <col width="15%"/>
                  </colgroup>
                  <thead>
                    <tr>
                      <th align="left">Covariate</th>
                      <th align="center">MEAN</th>
                      <th align="center">FA</th>
                      <th align="center">BA</th>
                      <th align="center">EC</th>
                      <th align="center">ES</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td align="left">(Intercept)</td>
                      <td align="center">-0.008</td>
                      <td align="center">-0.003</td>
                      <td align="center">-0.008</td>
                      <td align="center">-0.009</td>
                      <td align="center">0.031</td>
                    </tr>
                    <tr>
                      <td align="left">DISTKM_sqrt</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">0.081*</td>
                    </tr>
                    <tr>
                      <td align="left">FEELNAT</td>
                      <td align="center">0.202***</td>
                      <td align="center">0.169***</td>
                      <td align="center">0.188***</td>
                      <td align="center"/>
                      <td align="center">0.258***</td>
                    </tr>
                    <tr>
                      <td align="left">FEELNAT:LOC_SCEN</td>
                      <td align="center"/>
                      <td align="center">-0.002</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">FEELNAT:LOC_SENS</td>
                      <td align="center">0.054.</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">LCFOREST_sqrt</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">-0.090*</td>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">LNOISE</td>
                      <td align="center">0.177***</td>
                      <td align="center">0.133***</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">0.133**</td>
                    </tr>
                    <tr>
                      <td align="left">LNOISE:FEELNAT</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center">-0.006</td>
                    </tr>
                    <tr>
                      <td align="left">LOC_FAUN</td>
                      <td align="center"/>
                      <td align="center">0.176***</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">LOC_SCEN</td>
                      <td align="center"/>
                      <td align="center">0.164***</td>
                      <td align="center"/>
                      <td align="center">0.004</td>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">LOC_SENS</td>
                      <td align="center">0.104*</td>
                      <td align="center"/>
                      <td align="center">0.147***</td>
                      <td align="center">0.142***</td>
                      <td align="center">0.096*</td>
                    </tr>
                    <tr>
                      <td align="left">LOC_VISE</td>
                      <td align="center">0.173***</td>
                      <td align="center">0.128**</td>
                      <td align="center">0.122**</td>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">RL_NDVI</td>
                      <td align="center"/>
                      <td align="center">-0.133***</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                    <tr>
                      <td align="left">RL_NDVI:LOC_SCEN</td>
                      <td align="center"/>
                      <td align="center">0.024</td>
                      <td align="center"/>
                      <td align="center"/>
                      <td align="center"/>
                    </tr>
                  </tbody>
                </table>
              </table-wrap>
            </sec>
          </sec>
        </sec>
        <sec id="legacy-code-nb-2">
          <title>Legacy Code</title>
          <sec specific-use="notebook-content">
            <code language="r script">
# library(grpreg)
# fit &lt;- cv.grpreg(X = model.matrix(fit_MED_GIS)[,-1], y = D_trn[Mediator_vars[1:2]])
# coef(fit) |&gt; t()
# fit$beta
# plot(fit)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">
Y &lt;- D[]

library(mice, quietly = TRUE)
library(car, quietly = TRUE)
library(miceadds, quietly = TRUE)
data(nhanes2, package = "mice")
set.seed(9090)

mi.res &lt;- miceadds::mice.1chain(nhanes2, burnin = 4, iter = 20, Nimp = 8)
an2a &lt;- miceadds::mi.anova(mi.res = mi.res, formula = "bmi ~ age * chl")

mod1 &lt;- with(mi.res, stats::lm(bmi ~ age * chl))
mod0 &lt;- with(mi.res, stats::lm(bmi ~ age + chl))

mitml::testModels(model = mod1$analyses, null.model = mod0$analyses, method = "D1")
mitml::testModels(model = mod1$analyses, null.model = mod0$analyses, method = "D2")

an2b &lt;- miceadds::mi.anova(mi.res = mi.res, formula = "bmi ~ age * chl", type = 3)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">stop("this should not run")
Res1 &lt;- list()
for (mediator in Mediator_vars) {
  full_model &lt;- lm(as.formula(paste0(
    mediator, " ~ ", 
    "HM_NOISE_nrm * (", paste(GIS_vars, collapse = " + "), ")"
  )), D_trn)
  small_model &lt;- step(full_model, trace = FALSE, k = log(nrow(D_trn)))
  Res1[[mediator]] &lt;- lm(formula(small_model), D_tst)
}
lapply(Res1, summary)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">Res2 &lt;- list()
for (mediator in Mediator_vars) {
  full_model &lt;- lm(as.formula(paste0(
    mediator, " ~ ", 
    "HM_NOISE_nrm * (", paste(GIS_vars, collapse = " + "), ")"
  )), D_trn)
  small_model &lt;- step(full_model, trace = FALSE, k = log(nrow(D_trn)))
  Res2[[mediator]] &lt;- lm(formula(small_model), D_tst)
}
lapply(Res2, summary)
    </code>
          </sec>
          <preformat>library(knitr)
library(kableExtra)

# Function to extract coefficients with significance indicators
extract_coef_data &lt;- function(model_name, coef_data) {
  # Extract coefficient names, estimates, and p-values
  coef_names &lt;- rownames(coef_data)
  estimates &lt;- coef_data[, "Estimate"]
  p_values &lt;- coef_data[, "Pr(&gt;|t|)"]
  
  # Format estimates with significance stars
  formatted_coef &lt;- sapply(1:length(estimates), function(i) {
    est_str &lt;- sprintf("%.3f", estimates[i])
    if (p_values[i] &lt; 0.001) {
      paste0("**", est_str, "**")  # Bold for p &lt; 0.001
    } else {
      est_str
    }
  })
  
  # Create data frame
  data.frame(
    Model = model_name,
    Covariate = coef_names,
    Coefficient = formatted_coef,
    stringsAsFactors = FALSE
  )
}

# Manual data entry based on your results
# You would typically extract this from your model objects, but since you have text output:

model_results &lt;- list()

# FEELNAT model
feelnat_coef &lt;- data.frame(
  row.names = c("(Intercept)", "LCARTIF_sqrt", "RL_NDVI", "OVDIST_sqrt", "LCARTIF_sqrt:RL_NDVI"),
  Estimate = c(0.0618, -0.1524, 0.1498, 0.0270, 0.1146),
  `Pr(&gt;|t|)` = c(0.13260, 0.00770, 0.00063, 0.55112, 0.00446),
  check.names = FALSE
)
model_results[["FEELNAT"]] &lt;- extract_coef_data("FEELNAT", feelnat_coef)

# LNOISE model
lnoise_coef &lt;- data.frame(
  row.names = c("(Intercept)", "LCARTIF_sqrt", "RL_NOISE"),
  Estimate = c(-0.00097, -0.12357, -0.24203),
  `Pr(&gt;|t|)` = c(0.980, 0.011, 9.7e-07),
  check.names = FALSE
)
model_results[["LNOISE"]] &lt;- extract_coef_data("LNOISE", lnoise_coef)

# LOC_SENS model
loc_sens_coef &lt;- data.frame(
  row.names = c("(Intercept)", "HETER", "STRIMP999_sqrt"),
  Estimate = c(-0.000148, 0.129769, -0.072664),
  `Pr(&gt;|t|)` = c(0.99678, 0.00073, 0.05837),
  check.names = FALSE
)
model_results[["LOC_SENS"]] &lt;- extract_coef_data("LOC_SENS", loc_sens_coef)

# LOC_SOUN model
loc_soun_coef &lt;- data.frame(
  row.names = c("(Intercept)", "LCARTIF_sqrt", "HETER"),
  Estimate = c(0.000403, -0.175213, 0.109010),
  `Pr(&gt;|t|)` = c(0.9912, 2.9e-06, 0.0035),
  check.names = FALSE
)
model_results[["LOC_SOUN"]] &lt;- extract_coef_data("LOC_SOUN", loc_soun_coef)

# LOC_SCEN model
loc_scen_coef &lt;- data.frame(
  row.names = c("(Intercept)", "RL_NDVI"),
  Estimate = c(-0.00114, 0.21701),
  `Pr(&gt;|t|)` = c(0.97, 3.5e-09),
  check.names = FALSE
)
model_results[["LOC_SCEN"]] &lt;- extract_coef_data("LOC_SCEN", loc_scen_coef)

# LOC_VISE model
loc_vise_coef &lt;- data.frame(
  row.names = c("(Intercept)", "LCARTIF_sqrt"),
  Estimate = c(-0.000356, -0.071106),
  `Pr(&gt;|t|)` = c(0.992, 0.059),
  check.names = FALSE
)
model_results[["LOC_VISE"]] &lt;- extract_coef_data("LOC_VISE", loc_vise_coef)

# LOC_VEGE model
loc_vege_coef &lt;- data.frame(
  row.names = c("(Intercept)", "RL_NDVI", "JNYTIME_sqrt"),
  Estimate = c(-0.0192, 0.2195, -0.1139),
  `Pr(&gt;|t|)` = c(0.6111, 1.4e-08, 0.0027),
  check.names = FALSE
)
model_results[["LOC_VEGE"]] &lt;- extract_coef_data("LOC_VEGE", loc_vege_coef)

# LOC_FAUN model
loc_faun_coef &lt;- data.frame(
  row.names = c("(Intercept)", "LCARTIF_sqrt"),
  Estimate = c(-0.00127, -0.21409),
  `Pr(&gt;|t|)` = c(0.97, 1.1e-08),
  check.names = FALSE
)
model_results[["LOC_FAUN"]] &lt;- extract_coef_data("LOC_FAUN", loc_faun_coef)

# Combine all results
all_results &lt;- do.call(rbind, model_results)

# Create wide format table
results_wide &lt;- all_results %&gt;%
  select(Model, Covariate, Coefficient) %&gt;%
  tidyr::pivot_wider(names_from = Model, values_from = Coefficient, values_fill = "")

# Get all unique covariates and sort them (intercept first)
all_covariates &lt;- unique(all_results$Covariate)
covariate_order &lt;- c("(Intercept)", sort(all_covariates[all_covariates != "(Intercept)"]))

# Reorder rows
results_wide &lt;- results_wide %&gt;%
  slice(match(covariate_order, Covariate))

# Create the final table
print("Linear Model Results Summary")
print("Bold coefficients indicate p &lt; 0.001")
print("")

# Display as a nice table
kable(results_wide, 
      format = "pipe",
      align = c("l", rep("c", ncol(results_wide)-1))) %&gt;%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

# Alternative: Simple data frame for viewing
print(results_wide)
    </preformat>
        </sec>
      </sec>
    </body>
    <back>
</back>
  </sub-article>
</article>
