<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
  <front>
    <article-meta>
      <title-group>
        <article-title>PRS Analysis for WSL</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" corresp="yes">
          <contrib-id contrib-id-type="orcid">0009-0003-5147-8370</contrib-id>
          <name>
            <surname>Graz</surname>
            <given-names>Lukas</given-names>
          </name>
          <string-name>Lukas Graz</string-name>
          <role vocab="https://credit.niso.org" vocab-term="writing – original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
          <xref ref-type="aff" rid="aff-1">a</xref>
          <xref ref-type="corresp" rid="cor-1">*</xref>
        </contrib>
      </contrib-group>
      <aff id="aff-1">
        <institution-wrap>
          <institution>ETH Zurich</institution>
        </institution-wrap>
        <city>Zurich</city>
        <state>Switzerland</state>
        <ext-link ext-link-type="uri" xlink:href="www.ethz.ch">www.ethz.ch</ext-link>
      </aff>
      <author-notes>
        <corresp id="cor-1"/>
      </author-notes>
      <history/>
    </article-meta>
  </front>
  <body>
    <p>For the <bold>release notes</bold> see the corresponding
<ext-link ext-link-type="uri" xlink:href="https://github.com/LGraz/wsl--prs-analysis/releases">GitHub</ext-link>
page</p>
    <sec id="data-preparation">
      <title>Data Preparation</title>
      <sec id="train-test-split-for-inference">
        <title>Train Test Split for Inference</title>
        <p>Data was split into training and test sets (50/50) for hypothesis
    testing to ensure valid inference after feature selection.</p>
      </sec>
      <sec id="missing-values">
        <title>Missing Values</title>
        <p>Missing value imputation was performed using MissForest
    doi:10.1093/bioinformatics/btr597. This method leverages conditional
    dependencies between variables to predict missing values through an
    iterative random forest approach.</p>
        <p>To avoid introducing spurious correlations between different
    variable sets, we imputed the following data groups separately:</p>
        <list list-type="bullet">
          <list-item>
            <p>PRS variables on the complete dataset</p>
          </list-item>
          <list-item>
            <p>Mediators on training data only</p>
          </list-item>
          <list-item>
            <p>GIS variables on training data only</p>
          </list-item>
          <list-item>
            <p>Mediators for prediction analysis</p>
          </list-item>
          <list-item>
            <p>GIS variables for prediction analysis</p>
          </list-item>
          <list-item>
            <p>PRS variables for prediction analysis</p>
          </list-item>
        </list>
        <p>Mediators and GIS variables were intentionally not imputed on the
    test set to maintain valid inference, as MissForest does not provide
    a mechanism to propagate imputation uncertainty. An alternative
    would be the <monospace>mice</monospace>-routine, which could be
    implemented in future analyses. Missing values in the test set
    predictors remained untreated, which is justified under the missing
    completely at random (MCAR) assumption—where missing values occur
    independently of all other variables.</p>
        <p>For the prediction analysis, fewer statistical assumptions are
    required, so using the MissForest approach does not violate any
    assumptions.</p>
        <p>PRS variables could have been imputed separately for
    training/test sets and prediction analysis, but we prioritized
    simplicity as these variables serve only as response variables.</p>
        <p>Additionally, we compared MissForest with simpler imputation
    methods (variable-wise and observation-wise mean imputation) for the
    PRS variables. Results confirmed that MissForest consistently
    outperformed these alternatives.</p>
      </sec>
    </sec>
    <sec id="main-analysis">
      <title>Main Analysis</title>
      <sec id="response-variable-selection">
        <title>Response Variable Selection</title>
        <list list-type="bullet">
          <list-item>
            <p>Aggregated mean</p>
          </list-item>
          <list-item>
            <p>LA (Fascination)</p>
          </list-item>
          <list-item>
            <p>BA (Being Away)</p>
          </list-item>
          <list-item>
            <p>EC (Extent Coherence)</p>
          </list-item>
          <list-item>
            <p>ES (Compatibility)</p>
          </list-item>
        </list>
        <p><bold>PCA Verification</bold> of this approach. Key findings:</p>
        <list list-type="bullet">
          <list-item>
            <p>Data can be well approximated with 3-4 dimensions</p>
          </list-item>
          <list-item>
            <p>First dimension is close to weighted average of all variables
        (correlation &gt;0.99)</p>
          </list-item>
          <list-item>
            <p>EC (Extent Coherence) shows most divergence (see PC2)</p>
          </list-item>
          <list-item>
            <p>LA (Fascination) and BA (Being Away) show similarity (see
        PC1-PC3)</p>
          </list-item>
          <list-item>
            <p>Aggregated PRS variables justified by PCA results (similar
        rotation values), supporting use of mean</p>
          </list-item>
        </list>
      </sec>
      <sec id="prediction-analysis-with-machine-learning-methods">
        <title>Prediction Analysis with Machine Learning Methods</title>
        <p>Details and results in
    <ext-link ext-link-type="uri" xlink:href="notebooks/mlr3.qmd">the
    notebook</ext-link>.</p>
        <p>This section investigates predictive relationships between
    Perceived Restorativeness Scale (PRS) variables, mediator variables,
    and Geographical Information System (GIS) variables using various
    machine learning approaches. We employed a systematic methodology to
    quantify the predictive power of different variable
    combinations.</p>
        <sec id="methodological-approach">
          <title>Methodological Approach</title>
          <p>We evaluated multiple machine learning models using the mlr3
      framework (cite doi:10.21105/joss.01903) :</p>
          <list list-type="bullet">
            <list-item>
              <p>Linear models (baseline)</p>
            </list-item>
            <list-item>
              <p>XGBoost (gradient boosting with tree-based models and
          hyperparameter tuning for learning rate and tree depth) (cite
          arxiv:1603.02754)</p>
            </list-item>
            <list-item>
              <p>Random Forests (with default parameters) (cite
          doi:10.1023/A:1010933404324)</p>
            </list-item>
          </list>
          <p>Performance was measured as percentage of explained variance on
      hold-out data, calculated as (1 - MSE/Variance(y)), where MSE
      represents mean squared error.</p>
        </sec>
        <sec id="model-combinations">
          <title>Model Combinations</title>
          <p>To systematically explore predictive relationships, we tested
      four model configurations:</p>
          <list list-type="order">
            <list-item>
              <p>PRS ~ GIS: Predicting PRS variables using only GIS
          variables</p>
            </list-item>
            <list-item>
              <p>PRS ~ GIS + Mediators: Predicting PRS variables using both
          GIS and mediator variables</p>
            </list-item>
            <list-item>
              <p>PRS ~ Mediators: Predicting PRS variables using only
          mediator variables</p>
            </list-item>
            <list-item>
              <p>Mediators ~ GIS: Predicting mediator variables using GIS
          variables</p>
            </list-item>
          </list>
        </sec>
        <sec id="results">
          <title>Results</title>
          <list list-type="bullet">
            <list-item>
              <p>GIS shows limited predictive power for PRS on ES (5%
          variance explained)</p>
            </list-item>
            <list-item>
              <p>GIS + Mediators explain 25% of PRS variance</p>
            </list-item>
            <list-item>
              <p>Mediators alone explain majority of PRS variance</p>
              <list list-type="bullet">
                <list-item>
                  <p>GIS primarily helps with ES through tree-based
              methods</p>
                </list-item>
                <list-item>
                  <p>Suggests GIS effect is more interaction-based than
              direct</p>
                </list-item>
                <list-item>
                  <p>Similar reduction in tree-based methods observed in
              BA</p>
                </list-item>
              </list>
            </list-item>
          </list>
        </sec>
      </sec>
      <sec id="hypothesis-testing-investigation-of-variable-effects-on-perceived-restorativeness-scale">
        <title>Hypothesis Testing: Investigation of Variable Effects on
    Perceived Restorativeness Scale</title>
        <p>Details and results in
    <ext-link ext-link-type="uri" xlink:href="notebooks/hypothethis-tests.qmd">the
    notebook</ext-link>.</p>
        <p>Here we investigated which variables (including their
    interactions) influence PRS variables using multiple linear
    regression. With 190 variables (counting interactions), the variance
    inflation factor (VIF) was high and the multiple testing problem
    severe. We therefore implemented a stepwise feature selection using
    Bayesian Information Criterion (BIC) on the training data, starting
    with an empty model to help computational complexity. Selected
    features were subsequently used to fit models on the test set to
    obtain valid p-values. To keep the coefficients interpretable in the
    presence of interactions, each variable is scaled to mean 0 and
    standard deviation 1.</p>
        <sec id="model-specification-and-analysis">
          <title>Model Specification and Analysis</title>
          <p>The analysis systematically explored two key relationship
      pathways:</p>
          <list list-type="order">
            <list-item>
              <p>Mediators ~ (GIS)² - examining how environmental features
          predict psychological mediators</p>
            </list-item>
            <list-item>
              <p>PRS ~ (Mediators + GIS)² - investigating how both
          environmental features and psychological mediators contribute
          to perceived restorativeness</p>
            </list-item>
          </list>
          <p>For each target variable, we constructed a separate model using
      stepwise selection and evaluated it on the test dataset.</p>
        </sec>
        <sec id="results-1">
          <title>Results</title>
          <list list-type="bullet">
            <list-item>
              <p>For HM_Noise (now removed): Continuous mediator outperforms
          categorical (scaled to mean 0, sd 1)</p>
            </list-item>
            <list-item>
              <p>Full <monospace>mice</monospace> NA-handling likely
          unnecessary</p>
              <list list-type="bullet">
                <list-item>
                  <p>Models use few variables</p>
                </list-item>
                <list-item>
                  <p>Only LNOISE shows high NA count</p>
                </list-item>
                <list-item>
                  <p>Information detection still fails</p>
                </list-item>
              </list>
            </list-item>
            <list-item>
              <p>Significant edges remain in SEM (see all interactions)</p>
            </list-item>
          </list>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
</back>
  <sub-article article-type="notebook" id="nb-1-nb-1">
    <front-stub>
      <title-group>
        <article-title>Prediction Analysis for WSL</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Graz</surname>
            <given-names>Lukas</given-names>
          </name>
          <string-name>Lukas Graz</string-name>
        </contrib>
      </contrib-group>
    </front-stub>
    <body>
      <sec specific-use="notebook-content">
        <code language="r script">source("R/data_prep.R")
</code>
        <boxed-text>
          <preformat>Number of matches per filter criteria (not disjoint)
  Headphone  PRS_all_NA    Distance Activity_NA    Duration  HMNoise_NA 
        303         226         221         102          96          96 
JourneyTime 
         20 
Keep  1494 of 2206 observations</preformat>
        </boxed-text>
        <boxed-text>
          <preformat>Imputing PRS_orig_vars</preformat>
        </boxed-text>
        <boxed-text>
          <preformat>Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?
Warning in randomForest.default(x = obsX, y = obsY, ntree = ntree, mtry = mtry,
: The response has five or fewer unique values.  Are you sure you want to do
regression?</preformat>
        </boxed-text>
      </sec>
      <sec id="setup-nb-1">
        <title>Setup</title>
        <sec specific-use="notebook-content">
          <code language="r script">library(mlr3verse, quietly = TRUE)

mse &lt;- msrs(c("regr.mse"))

if (!interactive())
  lgr::get_logger("mlr3")$set_threshold("warn")

get_benchi_table &lt;- function(tasks, nfolds = 5) {
  set.seed(123)
  learners &lt;- lrns(c("regr.featureless", "regr.lm", "regr.xgboost", "regr.ranger"))
  learners$regr.xgboost$param_set$set_values(
    eta = 0.03, 
    nrounds = 300, 
    max_depth = 2
  )

  benchi &lt;- xfun::cache_rds({
    benchmark(benchmark_grid(
      tasks, 
      learners, 
      rsmp("cv", folds = nfolds)
    ))
  }, 
  file = "benchmark.rds", 
  dir = "cache/",
  hash = list(tasks, nfolds)
  )
  
  res &lt;- tidyr::pivot_wider(benchi$aggregate(mse), 
    id_cols = task_id,
    names_from = learner_id,
    values_from = regr.mse
  ) |&gt; as.data.frame()
  
  rownames(res) &lt;- res$task_id
  res &lt;- res[, -1]
  colnames(res) &lt;- gsub("regr.", "", colnames(res))
  stopifnot(any(colnames(res) == "featureless"))
  res &lt;- 1 - res / res$featureless
  res[, -1, drop = FALSE] |&gt; round(3)
}
  </code>
        </sec>
        <p>Testing prediction quality of GIS_vars -&gt; Mediators -&gt;
  PRS_vars using</p>
        <list list-type="bullet">
          <list-item>
            <p>Linear models</p>
          </list-item>
          <list-item>
            <p>Random forests (default parameters)</p>
          </list-item>
          <list-item>
            <p>XGBoost (with parameter tuning)</p>
          </list-item>
          <list-item>
            <p>LASSO (not shown since inferior)</p>
          </list-item>
        </list>
        <p>
          <bold>GIS Variables:</bold>
        </p>
        <sec specific-use="notebook-content">
          <code language="r script">GIS_vars
  </code>
          <boxed-text>
            <preformat> [1] "LCARTIF_sqrt"   "LCFOREST_sqrt"  "HETER"          "OVDIST_sqrt"   
 [5] "VIS5K_sqrt"     "RL_NDVI"        "RL_NOISE"       "DISTKM_sqrt"   
 [9] "JNYTIME_sqrt"   "STRIMP123_sqrt" "STRIMP999_sqrt"</preformat>
          </boxed-text>
        </sec>
        <p>
          <bold>Mediators:</bold>
        </p>
        <sec specific-use="notebook-content">
          <code language="r script">Mediator_vars
  </code>
          <boxed-text>
            <preformat>[1] "FEELNAT"  "LNOISE"   "LOC_SENS" "LOC_SOUN" "LOC_SCEN" "LOC_VISE" "LOC_VEGE"
[8] "LOC_FAUN"</preformat>
          </boxed-text>
        </sec>
        <sec id="prs-gis-nb-1">
          <title>PRS ~ GIS</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_GIS &lt;- lapply(PRS_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, GIS_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_GIS) 
    </code>
            <boxed-text>
              <preformat>         lm xgboost ranger
MEAN -0.002  -0.005 -0.036
LA   -0.002   0.013  0.002
BA   -0.006  -0.009 -0.021
EC    0.001  -0.027 -0.042
ES    0.048   0.041  0.026</preformat>
            </boxed-text>
          </sec>
          <p>GIS variables alone show poor predictive performance.</p>
        </sec>
        <sec id="prs-gis-mediators-nb-1">
          <title>PRS ~ GIS + Mediators</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_GIS_MED &lt;- lapply(PRS_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, Mediator_vars, GIS_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_GIS_MED) 
    </code>
            <boxed-text>
              <preformat>        lm xgboost ranger
MEAN 0.225   0.234  0.223
LA   0.236   0.260  0.248
BA   0.120   0.130  0.131
EC   0.042   0.012  0.021
ES   0.150   0.168  0.158</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="prs-mediators-nb-1">
          <title>PRS ~ Mediators</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_MED &lt;- lapply(PRS_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, Mediator_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_MED) 
    </code>
            <boxed-text>
              <preformat>        lm xgboost ranger
MEAN 0.224   0.235  0.191
LA   0.227   0.254  0.225
BA   0.132   0.145  0.112
EC   0.036   0.025 -0.020
ES   0.130   0.137  0.085</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="mediators-gis-nb-1">
          <title>Mediators ~ GIS</title>
          <sec specific-use="notebook-content">
            <code language="r script">tasks_MED_by_GIS &lt;- lapply(Mediator_vars, \(y) 
  as_task_regr(
    subset(Dmlr, select = c(y, GIS_vars)),
    target = y,
    id = y
  ))
get_benchi_table(tasks_MED_by_GIS)
    </code>
            <boxed-text>
              <preformat>            lm xgboost ranger
FEELNAT  0.126   0.136  0.111
LNOISE   0.096   0.070  0.080
LOC_SENS 0.020  -0.008 -0.025
LOC_SOUN 0.041   0.010 -0.001
LOC_SCEN 0.039   0.052  0.021
LOC_VISE 0.008  -0.029 -0.047
LOC_VEGE 0.052   0.025  0.032
LOC_FAUN 0.057   0.062  0.047</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="legacy-code-nb-1">
          <title>Legacy Code</title>
          <sec specific-use="notebook-content">
            <code language="r script">
# Get parameter estimates for XGBoost
t &lt;- as_task_regr(
  subset(Dmlr, select = c("FEELNAT", GIS_vars)),
  target = "FEELNAT"
)

l &lt;- lrn("regr.xgboost",
  nrounds = 500  # More iterations due to lower learning rate
)

# Create search space
ps &lt;- ps(
  max_depth = p_int(2, 3),
  eta = p_dbl(0.001, 0.3, tags = "logscale")
)

# Setup tuning
instance &lt;- ti(
  task = t,
  learner = l,
  resampling = rsmp("cv", folds = 3),
  measure = msr("regr.mse"),
  terminator = trm("none"),
  search_space = ps
)

# Grid search
tuner &lt;- mlr3tuning::tnr("grid_search")
tuner$optimize(instance)
instance$result
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">
library(randomForest)

fit &lt;- lm(as.formula(paste0(
    "cbind(", paste(PRS_vars, collapse = ", "), ")",
    " ~ ",
    paste(Mediator_vars, collapse = " + ")
  )), 
  D)
coef(fit) |&gt; round(2)

rsq.lm &lt;- sapply(summary(fit), \(x) x$r.sq)
rsq.rf &lt;- sapply(PRS_vars, \(x) {
  rf &lt;- randomForest(as.formula(paste0(
    x, " ~ ", paste(Mediator_vars, collapse = " + ")
  )), 
  D, na.action = na.omit
  ) 
  rf$rsq[500]
})

cbind(lm = rsq.lm, rf = rsq.rf) |&gt; round(2)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">
autoplot(mytsk1, type = "pairs")
mytsk1 &lt;- as_task_regr(
  subset(Dmlr, select = c("LA", Mediator_vars, GIS_vars)),
  feature = c(Mediator_vars, GIS_vars),
  target = "LA",
  id = "bla"
)

lrn_xgb &lt;- lrn("regr.xgboost")
lrn_avg &lt;- lrn("regr.featureless")
splits &lt;- partition(mytsk1)
lrn_xgb$train(mytsk1, splits$train)$predict(mytsk1, splits$test)$score(mse)
lrn_avg$train(mytsk1, splits$train)$predict(mytsk1, splits$test)$score(mse)
rr &lt;- resample(mytsk1, lrn_xgb, cv3)
rr$aggregate(mse)

learners &lt;- lrns(c("regr.featureless", "regr.lm", "regr.xgboost", "regr.ranger"))
learners$regr.xgboost$param_set$set_values(eta = 0.03, nrounds = 300, max_depth = 2)
learners &lt;- c("regr.featureless", "regr.lm")
    </code>
          </sec>
        </sec>
      </sec>
    </body>
    <back>
</back>
  </sub-article>
  <sub-article article-type="notebook" id="nb-4-nb-2">
    <front-stub>
      <title-group>
        <article-title>Hypothesis Testing</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Graz</surname>
            <given-names>Lukas</given-names>
          </name>
          <string-name>Lukas Graz</string-name>
        </contrib>
      </contrib-group>
    </front-stub>
    <body>
      <sec specific-use="notebook-content">
        <code language="r script">source("R/data_prep.R")
</code>
        <boxed-text>
          <preformat>Number of matches per filter criteria (not disjoint)
  Headphone  PRS_all_NA    Distance Activity_NA    Duration  HMNoise_NA 
        303         226         221         102          96          96 
JourneyTime 
         20 
Keep  1494 of 2206 observations</preformat>
        </boxed-text>
        <boxed-text>
          <preformat>Imputing PRS_orig_vars</preformat>
        </boxed-text>
        <code language="r script">options(digits = 3)

# interactive &lt;- function() FALSE
# D_trn$HM_NOISE_nrm &lt;- scale(D_trn$HM_NOISE)
# D_tst$HM_NOISE_nrm &lt;- scale(D_tst$HM_NOISE)
## No suspicious patterns in missing data
# mice::md.pattern(D[c(Mediator_vars, GIS_vars)[nNAs&gt;0]], plot = FALSE)
# mice::md.pattern(D[PRS_orig_vars])
</code>
      </sec>
      <sec id="linear-modeling-nb-2">
        <title>Linear Modeling</title>
        <sec id="imputation-with-missforest-on-training-data-nb-2">
          <title>Imputation with MissForest on Training Data</title>
          <sec specific-use="notebook-content">
            <code language="r script">sapply(D[Mediator_vars], \(x) sum(is.na(x)))
    </code>
            <boxed-text>
              <preformat> FEELNAT   LNOISE LOC_SENS LOC_SOUN LOC_SCEN LOC_VISE LOC_VEGE LOC_FAUN 
      16      291       28       30       36       62       69       88 </preformat>
            </boxed-text>
            <code language="r script">sapply(D[GIS_vars], \(x) sum(is.na(x)))
    </code>
            <boxed-text>
              <preformat>  LCARTIF_sqrt  LCFOREST_sqrt          HETER    OVDIST_sqrt     VIS5K_sqrt 
             0              0              0              0              0 
       RL_NDVI       RL_NOISE    DISTKM_sqrt   JNYTIME_sqrt STRIMP123_sqrt 
             0              0              0             86              0 
STRIMP999_sqrt 
             0 </preformat>
            </boxed-text>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script"># Mediator imputation
D_trn[Mediator_vars] &lt;- xfun::cache_rds({
  missForest(as.matrix(D_trn[Mediator_vars]))
  }, 
  file = "Mediator_imputation.rds", 
  dir = "cache/",
  hash = list(as.matrix(D_trn[Mediator_vars]))
)$ximp |&gt; as.data.frame()

# GIS imputation (missForest)
D_trn[GIS_vars] &lt;- xfun::cache_rds({
  missForest(as.matrix(D_trn[GIS_vars]))
  }, 
  file = "GIS_imputation.rds", 
  dir = "cache/",
  hash = list(as.matrix(D_trn[GIS_vars]))
)$ximp |&gt; as.data.frame()
    </code>
          </sec>
        </sec>
        <sec id="scaling-test-data-nb-2">
          <title>Scaling Test Data</title>
          <sec specific-use="notebook-content">
            <code language="r script">all_vars &lt;- c(Mediator_vars, GIS_vars, PRS_vars)
old_scale &lt;- t(sapply(D_tst[c(all_vars)], \(x) 
  c(mean = mean(x, na.rm = TRUE), sd = sd(x, na.rm = TRUE))))

D_tst[c(all_vars)] &lt;- lapply(D_tst[c(all_vars)], scale)

old_scale
    </code>
            <boxed-text>
              <preformat>                 mean     sd
FEELNAT         6.142  1.055
LNOISE          4.210  0.747
LOC_SENS        4.098  1.016
LOC_SOUN        4.296  0.947
LOC_SCEN        3.967  1.056
LOC_VISE        4.080  1.027
LOC_VEGE        4.343  0.859
LOC_FAUN        3.298  1.365
LCARTIF_sqrt    0.271  0.269
LCFOREST_sqrt   0.454  0.311
HETER           1.305  0.402
OVDIST_sqrt    21.797 10.144
VIS5K_sqrt      3.323  1.620
RL_NDVI         0.635  0.202
RL_NOISE       41.615  9.261
DISTKM_sqrt     1.473  1.156
JNYTIME_sqrt    3.830  2.247
STRIMP123_sqrt  6.555 10.739
STRIMP999_sqrt 47.557 13.162
PRS             4.987  0.879
LA              5.266  1.111
BA              5.140  1.156
EC              4.540  1.287
ES              5.006  1.426</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="testing-vif-nb-2">
          <title>Testing VIF</title>
          <sec specific-use="notebook-content">
            <code language="r script">car::vif(fit_PRS_MED &lt;- lm(as.formula(paste0(
  PRS_vars[1], 
  " ~ ", 
  paste(Mediator_vars, collapse = " + "), " + ",
  paste(GIS_vars,      collapse = " + ")
)), D_trn)) |&gt; summary()
    </code>
            <boxed-text>
              <preformat>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   1.21    1.46    1.94    2.03    2.24    4.99 </preformat>
            </boxed-text>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">suppressMessages(
car::vif(fit_PRS_MED &lt;- lm(as.formula(paste0(
  PRS_vars[1], 
  " ~ ", 
  "(", paste(Mediator_vars, collapse = " + "), 
     " + ", paste(GIS_vars, collapse = " + "), 
  ")^2"
)), D_trn))) |&gt; summary()
    </code>
            <boxed-text>
              <preformat>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
     12      81     147     205     269    1398 </preformat>
            </boxed-text>
          </sec>
          <p>Since we model with interactions later, these are also the
    p-values we want to use.</p>
        </sec>
        <sec id="all-interactions-mediators-gis2-nb-2">
          <title>All Interactions: Mediators ~ (GIS)^2</title>
          <sec specific-use="notebook-content">
            <code language="r script">Res3 &lt;- list()
for (mediator in Mediator_vars) {
  intercept_model &lt;- lm(as.formula(paste0(
    mediator, " ~ 1")), D_trn)
  step_model &lt;- step(intercept_model, 
    scope = as.formula(paste0(
      mediator, " ~ ", 
      "(", paste(GIS_vars, collapse = " + "), ")^2"
    )),
    trace = FALSE, k = log(nrow(D_trn))
  )
  Res3[[mediator]] &lt;- lm(formula(step_model), D_tst)
}
lapply(Res3, summary)
    </code>
            <boxed-text>
              <preformat>$FEELNAT

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-4.959 -0.391  0.264  0.607  1.685 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)            0.0618     0.0410    1.51  0.13260    
LCARTIF_sqrt          -0.1524     0.0570   -2.67  0.00770 ** 
RL_NDVI                0.1498     0.0436    3.43  0.00063 ***
OVDIST_sqrt            0.0270     0.0452    0.60  0.55112    
LCARTIF_sqrt:RL_NDVI   0.1146     0.0402    2.85  0.00446 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.948 on 733 degrees of freedom
  (9 observations deleted due to missingness)
Multiple R-squared:  0.106, Adjusted R-squared:  0.101 
F-statistic: 21.8 on 4 and 733 DF,  p-value: &lt;2e-16


$LNOISE

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.999 -0.527  0.012  0.676  1.622 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -0.00097    0.03862   -0.03    0.980    
LCARTIF_sqrt -0.12357    0.04841   -2.55    0.011 *  
RL_NOISE     -0.24203    0.04890   -4.95  9.7e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.945 on 596 degrees of freedom
  (148 observations deleted due to missingness)
Multiple R-squared:  0.11,  Adjusted R-squared:  0.107 
F-statistic: 36.6 on 2 and 596 DF,  p-value: 9.79e-16


$LOC_SENS

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.319 -0.217 -0.007  0.831  1.390 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    -0.000148   0.036675    0.00  0.99678    
HETER           0.129769   0.038233    3.39  0.00073 ***
STRIMP999_sqrt -0.072664   0.038328   -1.90  0.05837 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.993 on 730 degrees of freedom
  (14 observations deleted due to missingness)
Multiple R-squared:  0.0168,    Adjusted R-squared:  0.0141 
F-statistic: 6.22 on 2 and 730 DF,  p-value: 0.00209


$LOC_SOUN

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.623 -0.402  0.482  0.698  1.512 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   0.000403   0.036322    0.01   0.9912    
LCARTIF_sqrt -0.175213   0.037180   -4.71  2.9e-06 ***
HETER         0.109010   0.037186    2.93   0.0035 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.984 on 731 degrees of freedom
  (13 observations deleted due to missingness)
Multiple R-squared:  0.0344,    Adjusted R-squared:  0.0317 
F-statistic:   13 on 2 and 731 DF,  p-value: 2.82e-06


$LOC_SCEN

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.0383 -0.2135  0.0669  0.8101  1.8029 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.00114    0.03618   -0.03     0.97    
RL_NDVI      0.21701    0.03629    5.98  3.5e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.977 on 727 degrees of freedom
  (18 observations deleted due to missingness)
Multiple R-squared:  0.0469,    Adjusted R-squared:  0.0456 
F-statistic: 35.8 on 1 and 727 DF,  p-value: 3.48e-09


$LOC_VISE

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.0692 -0.1488 -0.0235  0.8511  1.0861 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)  -0.000356   0.037305   -0.01    0.992  
LCARTIF_sqrt -0.071106   0.037580   -1.89    0.059 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.998 on 714 degrees of freedom
  (31 observations deleted due to missingness)
Multiple R-squared:  0.00499,   Adjusted R-squared:  0.0036 
F-statistic: 3.58 on 1 and 714 DF,  p-value: 0.0589


$LOC_VEGE

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.971 -0.492  0.443  0.706  1.599 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   -0.0192     0.0378   -0.51   0.6111    
RL_NDVI        0.2195     0.0382    5.75  1.4e-08 ***
JNYTIME_sqrt  -0.1139     0.0379   -3.01   0.0027 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.98 on 671 degrees of freedom
  (73 observations deleted due to missingness)
Multiple R-squared:  0.0549,    Adjusted R-squared:  0.052 
F-statistic: 19.5 on 2 and 671 DF,  p-value: 6.03e-09


$LOC_FAUN

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-1.898 -0.914  0.300  0.796  1.744 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -0.00127    0.03685   -0.03     0.97    
LCARTIF_sqrt -0.21409    0.03697   -5.79  1.1e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.978 on 702 degrees of freedom
  (43 observations deleted due to missingness)
Multiple R-squared:  0.0456,    Adjusted R-squared:  0.0442 
F-statistic: 33.5 on 1 and 702 DF,  p-value: 1.05e-08</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="all-interactions-prs-mediators-gis2-nb-2">
          <title>All Interactions: PRS ~ (Mediators + GIS)^2</title>
          <sec specific-use="notebook-content">
            <code language="r script">Res4 &lt;- list()
for (prs in PRS_vars) {
  intercept_model &lt;- lm(as.formula(paste0(
    prs, " ~ 1")), D_trn)
  step_model &lt;- step(intercept_model, 
    scope = as.formula(paste0(
      prs, " ~ ", 
      "(", paste(GIS_vars, collapse = " + "), " + ", 
      paste(Mediator_vars, collapse = " + "), ")^2"
    )),
    trace = FALSE, k = log(nrow(D_trn))
  )
  Res4[[prs]] &lt;- lm(formula(step_model), D_tst)
}
lapply(Res4, summary)
    </code>
            <boxed-text>
              <preformat>$PRS

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-2.869 -0.564 -0.040  0.601  2.773 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)      -0.00667    0.03797   -0.18    0.861    
LOC_VISE          0.17340    0.04211    4.12  4.4e-05 ***
FEELNAT           0.20269    0.04304    4.71  3.1e-06 ***
LOC_SENS          0.10545    0.04245    2.48    0.013 *  
LNOISE            0.17705    0.04059    4.36  1.5e-05 ***
FEELNAT:LOC_SENS  0.05447    0.02800    1.95    0.052 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.895 on 567 degrees of freedom
  (174 observations deleted due to missingness)
Multiple R-squared:  0.192, Adjusted R-squared:  0.185 
F-statistic: 26.9 on 5 and 567 DF,  p-value: &lt;2e-16


$LA

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.391 -0.518  0.093  0.592  2.567 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)      -0.00247    0.03796   -0.06  0.94823    
LOC_SCEN          0.16395    0.04567    3.59  0.00036 ***
LOC_VISE          0.12820    0.04125    3.11  0.00198 ** 
FEELNAT           0.16832    0.04528    3.72  0.00022 ***
RL_NDVI          -0.13269    0.03906   -3.40  0.00073 ***
LOC_FAUN          0.17630    0.04167    4.23  2.7e-05 ***
LNOISE            0.13320    0.04017    3.32  0.00097 ***
LOC_SCEN:FEELNAT -0.00175    0.03148   -0.06  0.95556    
LOC_SCEN:RL_NDVI  0.02406    0.03405    0.71  0.48007    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.865 on 556 degrees of freedom
  (182 observations deleted due to missingness)
Multiple R-squared:  0.256, Adjusted R-squared:  0.245 
F-statistic: 23.9 on 8 and 556 DF,  p-value: &lt;2e-16


$BA

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.965 -0.508  0.071  0.649  2.406 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.00762    0.03574   -0.21  0.83115    
LOC_VISE     0.11948    0.04048    2.95  0.00326 ** 
FEELNAT      0.18740    0.03686    5.08  4.7e-07 ***
LOC_SENS     0.14894    0.04057    3.67  0.00026 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.948 on 700 degrees of freedom
  (43 observations deleted due to missingness)
Multiple R-squared:  0.114, Adjusted R-squared:  0.11 
F-statistic:   30 on 3 and 700 DF,  p-value: &lt;2e-16


$EC

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.9263 -0.5456 -0.0452  0.6817  2.3709 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   -0.00850    0.03665   -0.23  0.81665    
LOC_SENS       0.14389    0.04084    3.52  0.00045 ***
LCFOREST_sqrt -0.08886    0.03750   -2.37  0.01808 *  
LOC_SCEN       0.00289    0.04120    0.07  0.94407    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.985 on 719 degrees of freedom
  (24 observations deleted due to missingness)
Multiple R-squared:  0.03,  Adjusted R-squared:  0.0259 
F-statistic:  7.4 on 3 and 719 DF,  p-value: 6.88e-05


$ES

Call:
lm(formula = formula(step_model), data = D_tst)

Residuals:
   Min     1Q Median     3Q    Max 
-3.511 -0.539  0.144  0.685  2.301 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     0.03175    0.04168    0.76   0.4464    
LNOISE          0.13367    0.04325    3.09   0.0021 ** 
LOC_SENS        0.09971    0.04094    2.44   0.0152 *  
DISTKM_sqrt     0.08231    0.04048    2.03   0.0425 *  
FEELNAT         0.25862    0.04649    5.56  4.1e-08 ***
LNOISE:FEELNAT -0.00557    0.03433   -0.16   0.8711    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.952 on 576 degrees of freedom
  (165 observations deleted due to missingness)
Multiple R-squared:  0.142, Adjusted R-squared:  0.134 
F-statistic:   19 on 5 and 576 DF,  p-value: &lt;2e-16</preformat>
            </boxed-text>
          </sec>
        </sec>
        <sec id="legacy-code-nb-2">
          <title>Legacy Code</title>
          <sec specific-use="notebook-content">
            <code language="r script">
# library(grpreg)
# fit &lt;- cv.grpreg(X = model.matrix(fit_MED_GIS)[,-1], y = D_trn[Mediator_vars[1:2]])
# coef(fit) |&gt; t()
# fit$beta
# plot(fit)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">
Y &lt;- D[]

library(mice, quietly = TRUE)
library(car, quietly = TRUE)
library(miceadds, quietly = TRUE)
data(nhanes2, package = "mice")
set.seed(9090)

mi.res &lt;- miceadds::mice.1chain(nhanes2, burnin = 4, iter = 20, Nimp = 8)
an2a &lt;- miceadds::mi.anova(mi.res = mi.res, formula = "bmi ~ age * chl")

mod1 &lt;- with(mi.res, stats::lm(bmi ~ age * chl))
mod0 &lt;- with(mi.res, stats::lm(bmi ~ age + chl))

mitml::testModels(model = mod1$analyses, null.model = mod0$analyses, method = "D1")
mitml::testModels(model = mod1$analyses, null.model = mod0$analyses, method = "D2")

an2b &lt;- miceadds::mi.anova(mi.res = mi.res, formula = "bmi ~ age * chl", type = 3)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">stop("this should not run")
Res1 &lt;- list()
for (mediator in Mediator_vars) {
  full_model &lt;- lm(as.formula(paste0(
    mediator, " ~ ", 
    "HM_NOISE_nrm * (", paste(GIS_vars, collapse = " + "), ")"
  )), D_trn)
  small_model &lt;- step(full_model, trace = FALSE, k = log(nrow(D_trn)))
  Res1[[mediator]] &lt;- lm(formula(small_model), D_tst)
}
lapply(Res1, summary)
    </code>
          </sec>
          <sec specific-use="notebook-content">
            <code language="r script">Res2 &lt;- list()
for (mediator in Mediator_vars) {
  full_model &lt;- lm(as.formula(paste0(
    mediator, " ~ ", 
    "HM_NOISE_nrm * (", paste(GIS_vars, collapse = " + "), ")"
  )), D_trn)
  small_model &lt;- step(full_model, trace = FALSE, k = log(nrow(D_trn)))
  Res2[[mediator]] &lt;- lm(formula(small_model), D_tst)
}
lapply(Res2, summary)
    </code>
          </sec>
        </sec>
      </sec>
    </body>
    <back>
</back>
  </sub-article>
</article>
